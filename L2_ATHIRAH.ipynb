{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a75c7cba-11c0-434b-a27b-21dc2909e44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PART A: FEATURE SELECTION - BREAST CANCER WISCONSIN DATASET\n",
      "======================================================================\n",
      "\n",
      "1. DATASET DIMENSIONS:\n",
      "----------------------------------------\n",
      "dimension: (569, 30)\n",
      "Samples: 569, Features: 30\n",
      "\n",
      "2. FEATURES LIST:\n",
      "----------------------------------------\n",
      "30 Features:\n",
      "   0. mean radius\n",
      "   1. mean texture\n",
      "   2. mean perimeter\n",
      "   3. mean area\n",
      "   4. mean smoothness\n",
      "   5. mean compactness\n",
      "   6. mean concavity\n",
      "   7. mean concave points\n",
      "   8. mean symmetry\n",
      "   9. mean fractal dimension\n",
      "  10. radius error\n",
      "  11. texture error\n",
      "  12. perimeter error\n",
      "  13. area error\n",
      "  14. smoothness error\n",
      "  15. compactness error\n",
      "  16. concavity error\n",
      "  17. concave points error\n",
      "  18. symmetry error\n",
      "  19. fractal dimension error\n",
      "  20. worst radius\n",
      "  21. worst texture\n",
      "  22. worst perimeter\n",
      "  23. worst area\n",
      "  24. worst smoothness\n",
      "  25. worst compactness\n",
      "  26. worst concavity\n",
      "  27. worst concave points\n",
      "  28. worst symmetry\n",
      "  29. worst fractal dimension\n",
      "\n",
      "3. SAMPLE DISTRIBUTION:\n",
      "----------------------------------------\n",
      "Malignant samples: 212\n",
      "Benign samples: 357\n",
      "\n",
      "ID for malignant with size 212 :\n",
      "[np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(10), np.int64(11), np.int64(12), np.int64(13), np.int64(14), np.int64(15), np.int64(16), np.int64(17), np.int64(18), np.int64(22)] ...\n",
      "\n",
      "ID for benign with size 357 :\n",
      "[np.int64(19), np.int64(20), np.int64(21), np.int64(37), np.int64(46), np.int64(48), np.int64(49), np.int64(50), np.int64(51), np.int64(52), np.int64(55), np.int64(58), np.int64(59), np.int64(60), np.int64(61), np.int64(63), np.int64(66), np.int64(67), np.int64(68), np.int64(69)] ...\n",
      "\n",
      "4. FIRST THREE SAMPLES WITH FEATURE VALUES:\n",
      "----------------------------------------\n",
      "the first three samples with their features values:\n",
      "\n",
      "Sample 0:\n",
      "mean radius              : 1.7990e+01  mean texture             : 1.0380e+01  mean perimeter           : 1.2280e+02  mean area                : 1.0010e+03  mean smoothness          : 1.1840e-01  \n",
      "mean compactness         : 2.7760e-01  mean concavity           : 3.0010e-01  mean concave points      : 1.4710e-01  mean symmetry            : 2.4190e-01  mean fractal dimension   : 7.8710e-02  \n",
      "radius error             : 1.0950e+00  texture error            : 9.0530e-01  perimeter error          : 8.5890e+00  area error               : 1.5340e+02  smoothness error         : 6.3990e-03  \n",
      "compactness error        : 4.9040e-02  concavity error          : 5.3730e-02  concave points error     : 1.5870e-02  symmetry error           : 3.0030e-02  fractal dimension error  : 6.1930e-03  \n",
      "worst radius             : 2.5380e+01  worst texture            : 1.7330e+01  worst perimeter          : 1.8460e+02  worst area               : 2.0190e+03  worst smoothness         : 1.6220e-01  \n",
      "worst compactness        : 6.6560e-01  worst concavity          : 7.1190e-01  worst concave points     : 2.6540e-01  worst symmetry           : 4.6010e-01  worst fractal dimension  : 1.1890e-01  \n",
      "\n",
      "Sample 1:\n",
      "mean radius              : 2.0570e+01  mean texture             : 1.7770e+01  mean perimeter           : 1.3290e+02  mean area                : 1.3260e+03  mean smoothness          : 8.4740e-02  \n",
      "mean compactness         : 7.8640e-02  mean concavity           : 8.6900e-02  mean concave points      : 7.0170e-02  mean symmetry            : 1.8120e-01  mean fractal dimension   : 5.6670e-02  \n",
      "radius error             : 5.4350e-01  texture error            : 7.3390e-01  perimeter error          : 3.3980e+00  area error               : 7.4080e+01  smoothness error         : 5.2250e-03  \n",
      "compactness error        : 1.3080e-02  concavity error          : 1.8600e-02  concave points error     : 1.3400e-02  symmetry error           : 1.3890e-02  fractal dimension error  : 3.5320e-03  \n",
      "worst radius             : 2.4990e+01  worst texture            : 2.3410e+01  worst perimeter          : 1.5880e+02  worst area               : 1.9560e+03  worst smoothness         : 1.2380e-01  \n",
      "worst compactness        : 1.8660e-01  worst concavity          : 2.4160e-01  worst concave points     : 1.8600e-01  worst symmetry           : 2.7500e-01  worst fractal dimension  : 8.9020e-02  \n",
      "\n",
      "Sample 2:\n",
      "mean radius              : 1.9690e+01  mean texture             : 2.1250e+01  mean perimeter           : 1.3000e+02  mean area                : 1.2030e+03  mean smoothness          : 1.0960e-01  \n",
      "mean compactness         : 1.5990e-01  mean concavity           : 1.9740e-01  mean concave points      : 1.2790e-01  mean symmetry            : 2.0690e-01  mean fractal dimension   : 5.9990e-02  \n",
      "radius error             : 7.4560e-01  texture error            : 7.8690e-01  perimeter error          : 4.5850e+00  area error               : 9.4030e+01  smoothness error         : 6.1500e-03  \n",
      "compactness error        : 4.0060e-02  concavity error          : 3.8320e-02  concave points error     : 2.0580e-02  symmetry error           : 2.2500e-02  fractal dimension error  : 4.5710e-03  \n",
      "worst radius             : 2.3570e+01  worst texture            : 2.5530e+01  worst perimeter          : 1.5250e+02  worst area               : 1.7090e+03  worst smoothness         : 1.4440e-01  \n",
      "worst compactness        : 4.2450e-01  worst concavity          : 4.5040e-01  worst concave points     : 2.4300e-01  worst symmetry           : 3.6130e-01  worst fractal dimension  : 8.7580e-02  \n",
      "\n",
      "5. CHI-SQUARED TEST FEATURE SELECTION:\n",
      "----------------------------------------\n",
      "the top 5 features from p-values of chi-squared test:\n",
      "features p<0.05\n",
      "----------------------------------------\n",
      "  2 mean perimeter            0.000000e+00\n",
      "  3 mean area                 0.000000e+00\n",
      " 13 area error                0.000000e+00\n",
      " 22 worst perimeter           0.000000e+00\n",
      " 23 worst area                0.000000e+00\n",
      "\n",
      "6. F-TEST FEATURE SELECTION:\n",
      "----------------------------------------\n",
      "the top 5 features from p-values of F-test:\n",
      "features p<0.05\n",
      "----------------------------------------\n",
      " 27 worst concave points      1.969100e-124\n",
      " 22 worst perimeter           5.771397e-119\n",
      "  7 mean concave points       7.101150e-116\n",
      " 20 worst radius              8.482292e-116\n",
      "  2 mean perimeter            8.436251e-101\n",
      "\n",
      "7. COMMON FEATURES IN BOTH TESTS:\n",
      "----------------------------------------\n",
      "the same features from p-values of chi-squared test and F-test:\n",
      "[np.str_('mean perimeter'), np.str_('worst perimeter')]\n"
     ]
    }
   ],
   "source": [
    "# ==================== PART A: MACHINE LEARNING ====================\n",
    "# Feature Selection on Breast Cancer Wisconsin Dataset\n",
    "# NURUL ATHIRAH SYAFIQAH BINIT MOHD RAZALI\n",
    "\n",
    "# 1. Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PART A: FEATURE SELECTION - BREAST CANCER WISCONSIN DATASET\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 2. Load dataset\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "\n",
    "# Create DataFrame for better visualization\n",
    "df = pd.DataFrame(X, columns=cancer.feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "# 3. Print dimensions\n",
    "print(\"\\n1. DATASET DIMENSIONS:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"dimension: {X.shape}\")\n",
    "print(f\"Samples: {X.shape[0]}, Features: {X.shape[1]}\")\n",
    "\n",
    "# 4. Print all features\n",
    "print(\"\\n2. FEATURES LIST:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"{len(cancer.feature_names)} Features:\")\n",
    "for i, feature in enumerate(cancer.feature_names):\n",
    "    print(f\"  {i:2d}. {feature}\")\n",
    "\n",
    "# 5. Print malignant and benign samples\n",
    "print(\"\\n3. SAMPLE DISTRIBUTION:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "malignant_indices = np.where(y == 0)[0]\n",
    "benign_indices = np.where(y == 1)[0]\n",
    "\n",
    "print(f\"Malignant samples: {len(malignant_indices)}\")\n",
    "print(f\"Benign samples: {len(benign_indices)}\")\n",
    "\n",
    "# Print IDs (optional, as in example)\n",
    "print(f\"\\nID for malignant with size {len(malignant_indices)} :\")\n",
    "print(list(malignant_indices[:20]), \"...\")  # Show first 20\n",
    "\n",
    "print(f\"\\nID for benign with size {len(benign_indices)} :\")\n",
    "print(list(benign_indices[:20]), \"...\")  # Show first 20\n",
    "\n",
    "# 6. Print first three samples\n",
    "print(\"\\n4. FIRST THREE SAMPLES WITH FEATURE VALUES:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"the first three samples with their features values:\")\n",
    "for i in range(3):\n",
    "    print(f\"\\nSample {i}:\")\n",
    "    for j, (value, feature) in enumerate(zip(X[i], cancer.feature_names)):\n",
    "        if j % 5 == 0 and j > 0:\n",
    "            print()\n",
    "        print(f\"{feature:25}: {value:.4e}\", end=\"  \")\n",
    "    print()\n",
    "\n",
    "# 7. Chi-squared test feature selection\n",
    "print(\"\\n5. CHI-SQUARED TEST FEATURE SELECTION:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "chi2_selector = SelectKBest(score_func=chi2, k=5)\n",
    "chi2_selector.fit(X, y)\n",
    "\n",
    "# Get p-values\n",
    "chi2_pvalues = chi2_selector.pvalues_\n",
    "chi2_features_idx = chi2_selector.get_support(indices=True)\n",
    "\n",
    "print(\"the top 5 features from p-values of chi-squared test:\")\n",
    "print(\"features p<0.05\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Create DataFrame for chi2 results\n",
    "chi2_results = pd.DataFrame({\n",
    "    'Feature_Index': chi2_features_idx,\n",
    "    'Feature_Name': [cancer.feature_names[i] for i in chi2_features_idx],\n",
    "    'P_Value': chi2_pvalues[chi2_features_idx]\n",
    "})\n",
    "chi2_results = chi2_results.sort_values('P_Value')\n",
    "\n",
    "for idx, row in chi2_results.iterrows():\n",
    "    print(f\"{row['Feature_Index']:3d} {row['Feature_Name']:25} {row['P_Value']:.6e}\")\n",
    "\n",
    "# 8. F-test feature selection\n",
    "print(\"\\n6. F-TEST FEATURE SELECTION:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "f_selector = SelectKBest(score_func=f_classif, k=5)\n",
    "f_selector.fit(X, y)\n",
    "\n",
    "# Get p-values\n",
    "f_pvalues = f_selector.pvalues_\n",
    "f_features_idx = f_selector.get_support(indices=True)\n",
    "\n",
    "print(\"the top 5 features from p-values of F-test:\")\n",
    "print(\"features p<0.05\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Create DataFrame for F-test results\n",
    "f_results = pd.DataFrame({\n",
    "    'Feature_Index': f_features_idx,\n",
    "    'Feature_Name': [cancer.feature_names[i] for i in f_features_idx],\n",
    "    'P_Value': f_pvalues[f_features_idx]\n",
    "})\n",
    "f_results = f_results.sort_values('P_Value')\n",
    "\n",
    "for idx, row in f_results.iterrows():\n",
    "    print(f\"{row['Feature_Index']:3d} {row['Feature_Name']:25} {row['P_Value']:.6e}\")\n",
    "\n",
    "# 9. Find common features\n",
    "print(\"\\n7. COMMON FEATURES IN BOTH TESTS:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "chi2_feature_names = [cancer.feature_names[i] for i in chi2_features_idx]\n",
    "f_feature_names = [cancer.feature_names[i] for i in f_features_idx]\n",
    "\n",
    "common_features = set(chi2_feature_names) & set(f_feature_names)\n",
    "\n",
    "print(\"the same features from p-values of chi-squared test and F-test:\")\n",
    "if common_features:\n",
    "    print(f\"{list(common_features)}\")\n",
    "else:\n",
    "    print(\"No common features found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e4d131d-e780-42a8-b913-6f4b929c926e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\fyqaz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\fyqaz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\fyqaz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\fyqaz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (25.12.19)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\fyqaz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (0.7.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\fyqaz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\fyqaz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\fyqaz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\fyqaz\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\fyqaz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (6.33.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\fyqaz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\fyqaz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\fyqaz\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\fyqaz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\fyqaz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\fyqaz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\fyqaz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\fyqaz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\fyqaz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\fyqaz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (2.3.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\fyqaz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\fyqaz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\fyqaz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\fyqaz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\fyqaz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fyqaz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\fyqaz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: pillow in c:\\users\\fyqaz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (12.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\fyqaz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\fyqaz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.5)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\fyqaz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\fyqaz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
      "Requirement already satisfied: namex in c:\\users\\fyqaz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\fyqaz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in c:\\users\\fyqaz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\fyqaz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\fyqaz\\appdata\\roaming\\python\\python313\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\fyqaz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\fyqaz\\AppData\\Local\\Programs\\Python\\Python313\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51badcba-04a1-45fa-bd0d-9d9bb7914b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PART B: CONVOLUTIONAL NEURAL NETWORK (CNN)\n",
      "======================================================================\n",
      "\n",
      "CNN MODEL SUMMARY:\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">298</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">298</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">608</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">149</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">149</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">147</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">147</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">73</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">73</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">71</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">71</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">55,392</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">110,720</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">258,272</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10976</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10976</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">54,885</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m298\u001b[0m, \u001b[38;5;34m298\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m608\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m149\u001b[0m, \u001b[38;5;34m149\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m147\u001b[0m, \u001b[38;5;34m147\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m73\u001b[0m, \u001b[38;5;34m73\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m71\u001b[0m, \u001b[38;5;34m71\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │          \u001b[38;5;34m55,392\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33\u001b[0m, \u001b[38;5;34m33\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m110,720\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m224\u001b[0m)         │         \u001b[38;5;34m258,272\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_9 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m224\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10976\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10976\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │          \u001b[38;5;34m54,885\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">498,373</span> (1.90 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m498,373\u001b[0m (1.90 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">498,373</span> (1.90 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m498,373\u001b[0m (1.90 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==================== PART B: DEEP LEARNING ====================\n",
    "# Convolutional Neural Network (CNN) Architecture\n",
    "# NURUL ATHIRAH SYAFIQAH BINTI MOHD RAZALI\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PART B: CONVOLUTIONAL NEURAL NETWORK (CNN)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 1. Create sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# 2. First convolutional layer\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(300, 300, 2)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 3. Second convolutional layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 4. Third convolutional layer\n",
    "model.add(Conv2D(96, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 5. Fourth convolutional layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 6. Fifth convolutional layer\n",
    "model.add(Conv2D(224, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 7. Flatten layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# 8. Dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# 9. Dense layer with SoftMax activation\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# 10. Show model summary\n",
    "print(\"\\nCNN MODEL SUMMARY:\")\n",
    "print(\"-\" * 70)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b8b79ba-9651-415d-894e-eacc1f80c149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PART C: IDENTIFICATION OF TANDEM REPEATS\n",
      "======================================================================\n",
      "\n",
      "1. NUCLEOTIDE COUNTS:\n",
      "----------------------------------------\n",
      "Part 1 Counts: {'A': 2, 'C': 0, 'G': 1, 'T': 3}\n",
      "Part 2 Counts: {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
      "Part 3 Counts: {'A': 1, 'C': 0, 'G': 2, 'T': 3}\n",
      "\n",
      "2. MICROSATELLITE PROFILE COMPARISON:\n",
      "----------------------------------------\n",
      "Part 1 ('TTTAGA'): 1 repeats of 'TT'\n",
      "Part 2 ('TTCGTG'): 1 repeats of 'TT'\n",
      "Part 3 ('TTGTGA'): 1 repeats of 'TT'\n",
      "\n",
      "Microsatellite Profile Comparison Result:\n",
      "The profiles Part 1, Part 2, Part 3 have the same most repeats of TT.\n"
     ]
    }
   ],
   "source": [
    "# ==================== PART C: TANDEM REPEATS ====================\n",
    "# DNA Sequence Analysis - Nucleotide Counting and Microsatellite Comparison\n",
    "# NURUL ATHIRAH SYAFIQAH BINTI MOHD RAZALI\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PART C: IDENTIFICATION OF TANDEM REPEATS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# DNA sequences from the problem\n",
    "part1 = \"tttaga\"\n",
    "part2 = \"ttcgtg\"\n",
    "part3 = \"ttgtga\"\n",
    "\n",
    "# Convert to uppercase for consistency\n",
    "part1 = part1.upper()\n",
    "part2 = part2.upper()\n",
    "part3 = part3.upper()\n",
    "\n",
    "# ========== TASK 1: COUNT NUCLEOTIDES ==========\n",
    "def count_nucleotides(dna_sequence):\n",
    "    \"\"\"\n",
    "    Count the number of A, C, G, T in a DNA sequence.\n",
    "    Returns a dictionary with counts.\n",
    "    \"\"\"\n",
    "    counts = {'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
    "    \n",
    "    for nucleotide in dna_sequence:\n",
    "        if nucleotide in counts:\n",
    "            counts[nucleotide] += 1\n",
    "    \n",
    "    return counts\n",
    "\n",
    "print(\"\\n1. NUCLEOTIDE COUNTS:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Count nucleotides for each part\n",
    "counts1 = count_nucleotides(part1)\n",
    "counts2 = count_nucleotides(part2)\n",
    "counts3 = count_nucleotides(part3)\n",
    "\n",
    "print(f\"Part 1 Counts: {counts1}\")\n",
    "print(f\"Part 2 Counts: {counts2}\")\n",
    "print(f\"Part 3 Counts: {counts3}\")\n",
    "\n",
    "# ========== TASK 2: COMPARE MICROSATELLITE PROFILES ==========\n",
    "def count_microsatellite_repeats(dna_sequence, motif):\n",
    "    \"\"\"\n",
    "    Count the number of consecutive repeats of a microsatellite motif.\n",
    "    Returns the maximum consecutive repeats.\n",
    "    \"\"\"\n",
    "    motif = motif.upper()\n",
    "    dna_sequence = dna_sequence.upper()\n",
    "    max_repeats = 0\n",
    "    current_repeats = 0\n",
    "    i = 0\n",
    "    \n",
    "    while i < len(dna_sequence):\n",
    "        if dna_sequence[i:i+len(motif)] == motif:\n",
    "            current_repeats += 1\n",
    "            i += len(motif)\n",
    "        else:\n",
    "            if current_repeats > max_repeats:\n",
    "                max_repeats = current_repeats\n",
    "            current_repeats = 0\n",
    "            i += 1\n",
    "    \n",
    "    # Check at the end of sequence\n",
    "    if current_repeats > max_repeats:\n",
    "        max_repeats = current_repeats\n",
    "    \n",
    "    return max_repeats\n",
    "\n",
    "print(\"\\n2. MICROSATELLITE PROFILE COMPARISON:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Microsatellite motif\n",
    "motif = \"TT\"\n",
    "\n",
    "# Count repeats for each part\n",
    "repeats1 = count_microsatellite_repeats(part1, motif)\n",
    "repeats2 = count_microsatellite_repeats(part2, motif)\n",
    "repeats3 = count_microsatellite_repeats(part3, motif)\n",
    "\n",
    "print(f\"Part 1 ('{part1}'): {repeats1} repeats of '{motif}'\")\n",
    "print(f\"Part 2 ('{part2}'): {repeats2} repeats of '{motif}'\")\n",
    "print(f\"Part 3 ('{part3}'): {repeats3} repeats of '{motif}'\")\n",
    "\n",
    "# Determine result based on conditions\n",
    "print(\"\\nMicrosatellite Profile Comparison Result:\")\n",
    "\n",
    "max_repeats = max(repeats1, repeats2, repeats3)\n",
    "\n",
    "if max_repeats == 1:\n",
    "    # Find which profile has 1 repeat\n",
    "    profiles_with_max = []\n",
    "    if repeats1 == max_repeats:\n",
    "        profiles_with_max.append(\"Part 1\")\n",
    "    if repeats2 == max_repeats:\n",
    "        profiles_with_max.append(\"Part 2\")\n",
    "    if repeats3 == max_repeats:\n",
    "        profiles_with_max.append(\"Part 3\")\n",
    "    \n",
    "    if len(profiles_with_max) == 1:\n",
    "        print(f\"The profile {profiles_with_max[0]} has the most repeats of {motif}.\")\n",
    "    else:\n",
    "        profiles_str = \", \".join(profiles_with_max)\n",
    "        print(f\"The profiles {profiles_str} have the same most repeats of {motif}.\")\n",
    "\n",
    "elif max_repeats >= 2:\n",
    "    # Find which profiles have the max repeats (could be multiple)\n",
    "    profiles_with_max = []\n",
    "    if repeats1 == max_repeats:\n",
    "        profiles_with_max.append(\"Part 1\")\n",
    "    if repeats2 == max_repeats:\n",
    "        profiles_with_max.append(\"Part 2\")\n",
    "    if repeats3 == max_repeats:\n",
    "        profiles_with_max.append(\"Part 3\")\n",
    "    \n",
    "    profiles_str = \", \".join(profiles_with_max)\n",
    "    print(f\"The profiles {profiles_str} have the same most repeats of {motif}.\")\n",
    "\n",
    "else:\n",
    "    print(f\"No profile has any repeats of {motif}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc420202-d7e7-4fea-bc8a-2b9fd93e1e97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
